{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metadata generation complete. Saved to /Users/raffaelegiancotti/Desktop/projects/clinical_data_transformation/data/emar_nwicu_metadata.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
    "import numpy as np\n",
    "import logging\n",
    "import os\n",
    "\n",
    "\"\"\"\n",
    "After the model is fine-tuned, we use it to generate metadata from the name of the column and its context information(table name and dataset name)\n",
    "\n",
    "\"\"\"\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "model_path = \"/Users/raffaelegiancotti/Desktop/projects/clinical_data_transformation/New_model\"\n",
    "tokenizer = T5Tokenizer.from_pretrained(model_path)\n",
    "model = T5ForConditionalGeneration.from_pretrained(model_path)\n",
    "\n",
    "\n",
    "def generate_column_metadata(column_name, table_name, dataset_name):\n",
    "    try:\n",
    "        #input_text_desc = f\"Column '{column_name}' from table '{table_name}' from '{dataset_name}' dataset. Extract metadata file:\"\n",
    "        #input_text_abbr = f\"If I provide you with the column '{column_name}' from the '{table_name}' table in the '{dataset_name}' dataset, how many possible ways can you abbreviate this term, and how many related abbreviations can you identify that convey the same meaning?\"\n",
    "        input_text_descr = f\"Give a description of {column_name} from {table_name} from {dataset_name} dataset.\"\n",
    "        inputs_desc = tokenizer(input_text_descr, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
    "        #inputs_abbr = tokenizer(input_text_abbr, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs_desc = model.generate(inputs_desc['input_ids'], max_length=1024)\n",
    "            #outputs_abbr = model.generate(inputs_abbr['input_ids'], max_length=1024)\n",
    "\n",
    "        description = tokenizer.decode(outputs_desc[0], skip_special_tokens=True)\n",
    "        #abbreviations = tokenizer.decode(outputs_abbr[0], skip_special_tokens=True)\n",
    "\n",
    "        return description#, abbreviations\n",
    "    except Exception as e:\n",
    "        print(f\"Error generating metadata for column '{column_name}': {e}\")\n",
    "        return None, None\n",
    "\n",
    "def generate_metadata_for_table(df, table_name, dataset_name, batch_size=8):\n",
    "    metadata = []\n",
    "    columns = df.columns.tolist()\n",
    "    \n",
    "    metadata.append({\n",
    "    \"Table Name\": table_name,\n",
    "    \"Dataset Name\": dataset_name,\n",
    "    \"Table description\": \"A table containing...\", #to define\n",
    "    \"Number of Rows\": len(df),\n",
    "    \"Number of Columns\": len(df.columns)})\n",
    "    \n",
    "    for i in range(0, len(columns), batch_size):\n",
    "        batch_columns = columns[i:i + batch_size]\n",
    "        batch_inputs_desc = []\n",
    "        #batch_inputs_abbr = []\n",
    "        \n",
    "        for column in batch_columns:\n",
    "            input_text_desc = f\"Give a description of {column} from {table_name} from {dataset_name}\"\n",
    "            #input_text_abbr = f\"If I provide you with the column '{column}' from the '{table_name}' table in the '{dataset_name}' dataset, how many possible ways can you abbreviate this term, and how many related abbreviations can you identify that convey the same meaning?\"\n",
    "            batch_inputs_desc.append(input_text_desc)\n",
    "            #batch_inputs_abbr.append(input_text_abbr)\n",
    "        \n",
    "        # Tokenize and process in batches\n",
    "        inputs_desc = tokenizer(batch_inputs_desc, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
    "        #inputs_abbr = tokenizer(batch_inputs_abbr, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            outputs_desc = model.generate(inputs_desc['input_ids'], max_length=1024)\n",
    "            #outputs_abbr = model.generate(inputs_abbr['input_ids'], max_length=1024)\n",
    "            \n",
    "        for idx, column in enumerate(batch_columns):\n",
    "            description = tokenizer.decode(outputs_desc[idx], skip_special_tokens=True)\n",
    "            #abbreviations = tokenizer.decode(outputs_abbr[idx], skip_special_tokens=True)\n",
    "            sample_data = df[column].sample(5)\n",
    "            data_type = str(df[column].dtype)\n",
    "            \n",
    "            metadata.append({\n",
    "                \"Column name\": column,\n",
    "                \"Sample data\": list(sample_data),\n",
    "                \"Data type\": data_type,\n",
    "                \"Column description\": description#,\n",
    "                #\"Abbreviations\": abbreviations\n",
    "            })\n",
    "    \n",
    "    return pd.DataFrame(metadata)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    file_path = \"/Users/raffaelegiancotti/Desktop/projects/clinical_data_transformation/data/northwestern-icu-nwicu-database-0.1.0/data/nw_hosp/emar.csv\"\n",
    "    df = pd.read_csv(file_path)\n",
    "    table_name = os.path.splitext(os.path.basename(file_path))[0]\n",
    "    dataset_name = \"nwicu\"  \n",
    "    generated_path = \"/Users/raffaelegiancotti/Desktop/projects/clinical_data_transformation/data/emar_nwicu_metadata.csv\"  \n",
    "    \n",
    "    metadata_df = generate_metadata_for_table(df, table_name, dataset_name)\n",
    "    \n",
    "    \n",
    "    metadata_df.to_csv(generated_path, index=False)\n",
    "    \n",
    "    print(\"Metadata generation complete. Saved to\", generated_path)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
